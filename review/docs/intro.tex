% !TEX root = ../literature.tex
\section{Introduction}
\cite{Weiser:1991} points out:
 
{\em``Ubiquitous computing names the third wave in computing, just now beginning. First were mainframes, each shared by lots of people. Now we are in the personal computing era, person and machine staring uneasily at each other across the desktop. Next comes ubiquitous computing, or the age of calm technology, when technology recedes into the background of our lives.''}.

We could contend and regard that the latest incarnation of Weiser's vision is cross-device interaction, where ideally joining two devices would lead to single seamless and Natural User Interface (NUI), flexible and not restricted to a few configurations.
In order for this interaction to happen we need to remain as close as possible to the real world, and ``human interaction with the world is multi-modal, and rich multi-modal interaction is part of what defines a natural experience.''[2]. 
Ideally we would see a combination of multiple modalities for instance gestures, augmented reality, touch, voice recognition etc. 
Researchers have made and published breakthroughs and designers constructed innovation design in each modality individually, however there has only been little research and work in combining them.[2] 
It is possible for existence of untapped opportunities in the integration of multiple natural user interaction modalities for enriching the cross-device experience with handheld devices and large public displays. 
In this paper we review the research that has been done within interaction with large displays. 
This has been done to map the current understanding and practices, thereby helping future researchers, within this field, to gain a perspective as well as identifying possible untapped opportunities for future work.